{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Algorithmic Complexity\n",
    "‚ÄúAlgorithmic Complexity‚Äù refers to the computing resources needed by an algorithm to solve a problem. These computing resources can be the time taken for program execution (**time compexity**), or the space used in memory during its execution (**space complexity**).\n",
    "\n",
    "The aim to minimize these resourses, so an algorithm takes less time and space is considered more efficient.\n",
    "\n",
    "It is important to analyze and understand the algorithmic complexity to choose or design the most efficient algorithm for a specific use-case.\n",
    "\n",
    "## Time vs Space complexity\n",
    "\n",
    "In the context of algorithmic complexity, ‚Äútime‚Äù refers to the amount of computational time that the algorithm takes to execute, while ‚Äúspace‚Äù refers to the amount of memory that algorithm needs to complete its operation.\n",
    "\n",
    "### Time complexity\n",
    "The time complexity measures the performance of an algorithm in terms of how much time it takes to complete as the size of the input grows.\n",
    "\n",
    "The time complexity depends on the size of the input. The time is measured in relation how the input grows.\n",
    "\n",
    "## Space complexity\n",
    "The space complexity measures how much memory (or space) the algorithm uses as the size of input grows.\n",
    "\n",
    "The space complexity refers to the amount of memory (RAM) an algorithm needs to complete its task. This includes all memory used by the variables, data structures, input data, and any extra space the algorithm might need during execution.\n",
    "\n",
    "The total amount of memory used by an algorithm can be divided into two parts:\n",
    "\n",
    "1. **Input Size**: This refers to the memory required to store the input data itself. It is the space the algorithm needs just to hold the data it will work on. The size of the input directly impacts the space complexity, because as the input grows, so does memory needed to store it.\n",
    "2. **Auxiliary Space:** This refers to any extra memory the algorithm needs to perform its task in addition to the memory used for the input.\n",
    "\n",
    "    This includes temporary variables, additional data structures, and any other space that isn‚Äôt part of the input but is necessary for the algorithm to run.\n",
    "\n",
    "    When we calculate **space complexity**, we typically include **both**:\n",
    "\n",
    "    - **The input size**: the memory used to store the input data itself.\n",
    "    - **The auxiliary space**: the memory used for any extra variables, data structures, or temporary storage.\n",
    "\n",
    "It‚Äôs important to note that time and space are often at odds with each other; optimizing an algorithm to be quicker often requires taking up more memory, and decreasing memory usage can often make the algorithm slower. This is known as the **space-time tradeoff.**\n",
    "\n",
    "## Big O Notation - Upper Bound\n",
    "\n",
    "### What is Big-O Notation?\n",
    "\n",
    "**Big-O**, commonly referred to as ‚Äú**Order of**‚Äù, is a way to express the¬†**upper bound**¬†of an algorithm‚Äôs time complexity, since it analyses the¬†**worst-case**¬†situation of the algorithm.\n",
    "It provides an¬†**upper limit**¬†on the time taken by an algorithm in terms of the size of the input.¬†\n",
    "\n",
    "It‚Äôs denoted as¬†**O(f(n))**, where¬†**f(n)**¬†is a function that represents the number of operations (steps) that an algorithm performs to solve a problem of size¬†**n**.\n",
    "\n",
    "<aside>\n",
    "üí°\n",
    "\n",
    "***Big-O notation** is used to describe the performance or complexity of an algorithm. Specifically, it describes the **worst-case scenario** in terms of **time** or **space complexity.***\n",
    "\n",
    "</aside>\n",
    "\n",
    "**Important Point:**\n",
    "\n",
    "- **Big O notation**¬†only describes the asymptotic behavior of a function, not its exact value.\n",
    "- The¬†**Big O notation**¬†can be used to compare the efficiency of different algorithms or data structures.\n",
    "- **Asymptotic behavior**: Big-O notation is concerned with how an algorithm behaves for **very large input sizes** (as n approaches infinity). As we've seen, for large n, the higher-order terms completely dominate the lower-order terms and constants.\n",
    "- For small values of n, constants and lower-order terms might matter, but **Big-O notation is designed to simplify the analysis** by focusing on the dominant term for large n. That‚Äôs why we ignore constants and lower-order terms‚Äîthey don‚Äôt affect the algorithm's efficiency when n is large enough.\n",
    "\n",
    "![bigO](https://media.geeksforgeeks.org/wp-content/uploads/20240329121436/big-o-analysis-banner.webp)\n"
   ],
   "id": "df268e1607816d3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The notation *f(n) = O(g(n))* means that for sufficiently large *n*, the function *f(n)* does not grow faster than a constant multiple of *g(n)*. In other words:\n",
    "\n",
    "$$\n",
    "f(n) \\leq c \\cdot g(n) \\quad \\text{for all } n \\geq n_0\n",
    "$$\n",
    "\n",
    "This means:\n",
    "\n",
    "- *g(n)* is a function that represents an upper bound for *f(n)*.\n",
    "- The function *f(n)* may fluctuate for small values of *n*, but after a certain point (*n‚ÇÄ*), it will always stay below some constant multiple of *g(n)*.\n",
    "\n",
    "The __main point of algorithmic complexity__ is to predict how an algorithm's runtime and memory usage grow as the input size increases, so we can choose the most efficient algorithm for a given task, especially when working with large data.\n",
    "\n",
    "Slow algorithms might work fine for small inputs but become unusable with large data.\n",
    "Memory-hungry algorithms can crash a program or slow down a system.\n",
    "\n"
   ],
   "id": "f9f235b0367247b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Growth hierarchy\n",
    "When evaluating an algorithm's efficiency, we must take into consideration the efficiency of each step withing the algorithm, we then find the highest order step, or step that has the worst performance, and prioritize it over all of the better performing steps.\n",
    "\n",
    "![order](https://miro.medium.com/v2/resize:fit:1300/1*jRE5c9YXdi-hqOzX5WbF6A.png)\n",
    "\n"
   ],
   "id": "99e1df93be83bbcb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "68cbbc3dcec7f794"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Common runtimes\n",
   "id": "474a004095b30803"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Constant O(1)\n",
    "Runtime doesn't depend on the size of the input.\n",
    "No matter how large the input is, the algorithm performs the same number of steps. The number of operations doesn't grow with the size input.\n",
    "\n",
    "#### Characteristics:\n",
    "* Fastest possible time complexity\n",
    "* Ideal for operations that access data directly without iteration.\n",
    "* Runtime is constant, even if input size increases to a billion.\n",
    "\n",
    "\n"
   ],
   "id": "5cd097651d8703ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "| Input Size (n)       | 1 | 10 | 1000 | 1,000,000 |\n",
    "|----------------------|---|----|------|-----------|\n",
    "| Time taken (steps)   | 1 |  1 |    1 |         1 |\n",
    "\n"
   ],
   "id": "83fce618c98679c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def constant_func(arr): # the function does nothing with the list, no `````````````````````````matter how big it is\n",
    "    result = 100 * 1000 # the expression always results in the same value                       and always take the same amount of time\n",
    "    return result"
   ],
   "id": "578f9735e7316557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Linear O(n)\n",
    "Runtime grows linearly with the size of the input.\n",
    "If the input doubles, the time it takes roughly double too.\n",
    "#### Characteristics:\n",
    "* There's typically one pass through the input.\n",
    "* Each element is processed once.\n",
    "* Runtime increases directly proportional to input size.\n",
    "\n",
    "Even if you do multiple constant-time operations inside the loop, it's still O(n).\n",
    "You can't do better than O(n), if you must examine every element.\n",
    "\n",
    "| Input Size (n)    | 1 | 10 | 100 | 1000 |\n",
    "|-------------------|---|----|-----|------|\n",
    "| Time taken(steps) | 1 | 10 | 100 | 1000 |\n"
   ],
   "id": "3458bf32b834cd86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def linear_func(arr):\n",
    "    for element in arr: #O(n), the function iterates through                                      each element in the list\n",
    "        print(1000 * 100000) # constant time O(1), the statement always takes                       the same amount of time\n",
    "\n",
    "arr = [1, 2, 3, 4, 5, 6, 7]\n",
    "linear_func(arr)"
   ],
   "id": "76628ef9345d7335",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quadratic O(n^2)\n",
    "An algorithm grows proportionally to the square of the input size.\n",
    "That means if the input size doubles, the number of operations becomes four times bigger.\n",
    "\n",
    "#### Characteristics\n",
    "* Often involves nested loops - one loop inside another.\n",
    "* Performance drops very fast as input grows.\n",
    "* OK for very small inputs, but quickly becomes inefficient."
   ],
   "id": "1ae019b295e56162"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def square(n):\n",
    "    matrix = np.empty((n, n))\n",
    "    for i in range(n):    # O(n)\n",
    "        for j in range(n): #O(n) => the function's runtime is quadratic O(n^2)\n",
    "            matrix[i, j] = j\n",
    "    print(matrix)\n",
    "    print(matrix.shape) #(n, n)\n",
    "    print(matrix.ndim)  #2\n",
    "    print(matrix.size)  #n^2\n",
    "\n",
    "square(5)"
   ],
   "id": "2119100c966e8734",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cubic O(n^3)\n",
    "The number of operations grows proportionally to the cube of the input size.\n",
    "#### Characteristics\n",
    "* Typically, involves three nested loops.\n",
    "* 3D matrices, graph algorithms, dynamic programming.\n",
    "* Becomes impractical very quickly."
   ],
   "id": "f37347aa05d6ed37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cube(n):\n",
    "    matrix = np.empty((n, n, n))\n",
    "    for i in range(n): # O(n)\n",
    "        for j in range(n): # O(n)\n",
    "            for k in range(n): # O(n) => the function's runtime is O(n^3)\n",
    "                matrix[i, j, k] = k\n",
    "    print(matrix)\n",
    "    print(matrix.shape) #(n, n, n)\n",
    "    print(matrix.ndim)  # n\n",
    "    print(matrix.size)  # n^3\n",
    "\n",
    "cube(5)"
   ],
   "id": "c227c99f56a587a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Logarithmic O(log n)\n",
    "The number of operations grows logarithmically as the input size increases.\n",
    "This means each step reduces the problem size by a constant factor ( usually dividing in halve).\n",
    "So instead of checking every element, the algorithm skips large portions of the data.\n",
    "#### Characteristics:\n",
    "* Extremely efficient for large inputs.\n",
    "* Often used with divide and conquer algorithms.\n",
    "* Input size shrinks rapidly - very few steps needed even for huge inputs.\n",
    "\n",
    "| Input size (n)      | 1 | 10 | 100 | 1,000 | 1,000,000 |\n",
    "|---------------------|---|----|-----|-------|-----------|\n",
    "| Steps (log n)       | 0 |  4 |   7 |    10 |        20 |\n",
    "\n"
   ],
   "id": "286c35214e889979"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recursive implementation of O(log n)\n",
    "def log_rec_func(n):\n",
    "    if n == 0:\n",
    "        return \"Done\"\n",
    "    n //= 2\n",
    "    return log_rec_func(n)\n",
    "log_rec_func(8)"
   ],
   "id": "b2e7b1206f0d2a1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Non-recursive implementation of O(log n)\n",
    "def log_no_rec_func(n): # n = 8     iteration 1: n = 8 // 2 = 4\n",
    "    while n > 1:        #           iteration 2: n = 4 // 2 = 2\n",
    "        n //= 2         #           iteration 3: n = 2 // 2 = 1\n",
    "                        # The number of iterations = log 8 = 3"
   ],
   "id": "d37060c32fa1b97b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Binary Search\n",
   "id": "8b575dacad65a089"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Non-recursive implementation of binary search\n",
    "\n",
    "def binary_search(arr, item):\n",
    "    low = 0\n",
    "    high = len(arr) - 1\n",
    "\n",
    "    while low  <= high:\n",
    "        mid = (low + high) // 2\n",
    "        guess = arr[mid]\n",
    "        if guess == item:\n",
    "            return mid\n",
    "        if guess > item:\n",
    "            high = mid - 1\n",
    "        else:\n",
    "            low = mid + 1\n",
    "    return None\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5, 6]\n",
    "print(binary_search(my_list, 4))"
   ],
   "id": "4a10c5aca06c45ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recursive implementation\n",
    "\n",
    "def binary_search_recursive(arr, item, low, high):\n",
    "    mid = (low + high) // 2\n",
    "    guess = arr[mid]\n",
    "    if guess == item:\n",
    "        return mid\n",
    "    if guess > item:\n",
    "        return binary_search_recursive(arr, item, low, mid - 1)\n",
    "    if guess < item:\n",
    "        return binary_search_recursive(arr, item, mid + 1, high)\n",
    "    return None\n",
    "my_list = [1, 2, 3, 4, 5, 6]\n",
    "print(binary_search_recursive(my_list, 4, 0, len(my_list) - 1))"
   ],
   "id": "cf9e884261f0999b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Linearithmic O(n log n)\n",
    "The algorithm performs log n levels of work, and at each level, it processes n elements.\n",
    "Total work = log n levels * n operations per level = O(n log n)."
   ],
   "id": "36a84c0be6f052b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def n_LogN_func(n):\n",
    "    y = n\n",
    "    while n > 1: # O(log n)\n",
    "        n //= 2\n",
    "        for i in range(1, y + 1): # O(n)\n",
    "            print(i)\n",
    "n_LogN_func(4)"
   ],
   "id": "441c399643a91a84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Merged Sort",
   "id": "7fef84724a8b7b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# O(log n) - the depth of recursion\n",
    "# O(n) - the work on every level of merging => merge_sort - O(n log n)\n",
    "def merge_sort(arr):\n",
    "    if len(arr) < 2:\n",
    "        return arr\n",
    "\n",
    "    middle_index = len(arr) // 2\n",
    "    left_array = arr[:middle_index]\n",
    "    right_array = arr[middle_index:]\n",
    "\n",
    "    return merge(merge_sort(left_array), merge_sort(right_array))\n",
    "\n",
    "def merge(left_arr, right_arr):\n",
    "    result = []\n",
    "    left_index = 0\n",
    "    right_index = 0\n",
    "\n",
    "    while left_index < len(left_arr) and right_index < len(right_arr):\n",
    "        if left_arr[left_index] < right_arr[right_index]:\n",
    "            result.append(left_arr[left_index])\n",
    "            left_index += 1\n",
    "        else:\n",
    "            result.append(right_arr[right_index])\n",
    "            right_index += 1\n",
    "\n",
    "    result.extend(left_arr[left_index:])\n",
    "    result.extend(right_arr[right_index:])\n",
    "    return result\n",
    "\n",
    "print(merge_sort([12, 3, 16, 6, 5, 1]))\n"
   ],
   "id": "d39d3e69e4dbb788",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exponential O(2^n)\n",
    "The runtime doubles with every additional input element."
   ],
   "id": "34de4759a7c58a7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# On every level we make 2^n calls of the initial function\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "print(fib(4))"
   ],
   "id": "9364e32e7fd9c653",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Factorial O(n!)\n",
    "The runtime of operations grows factorially with the input size."
   ],
   "id": "ba33b47eff51482d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def f(n):\n",
    "    if n == 0:\n",
    "        print(\"***************\")\n",
    "        return\n",
    "    for _ in range(n):\n",
    "        f(n - 1)"
   ],
   "id": "226430f0d8c64aad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Big Omega Œ© Notation - Lower Bound\n",
    "\n"
   ],
   "id": "98e5f21c701e672d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It defines a lower bound on the growth rate of a function.\n",
    "It tells use the minimum amount of time (or space) an algorithm will take for large inputs.\n",
    "\n",
    "A function **T(n) = Œ©(f(n))** if there exist constants **c > 0** and **n‚ÇÄ ‚â• 0** such that:\n",
    "\n",
    "$$\n",
    "T(n) \\geq c \\cdot f(n) \\quad \\text{for all } n \\geq n‚ÇÄ\n",
    "$$\n",
    "\n",
    "The algorithm won't run faster than __f(n)__ as input.\n",
    "\n",
    "Example:\n",
    "If **T(n) = 3n + 2**, then:\n",
    "\n",
    "$$\n",
    "T(n) = \\Omega(n)\n",
    "$$\n",
    "Because\n",
    "$$\n",
    "3n + 2 \\geq c \\cdot n  for  c = 2, n \\geq 1\n",
    "$$\n",
    "\n"
   ],
   "id": "7803186e6395c474"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Big Theta (Œò) Notation ‚Äì Tight Bound",
   "id": "d8e271945c92bb00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Big Theta gives a tight (exact) bound ‚Äî both an upper and lower bound on an algorithm's growth rate.\n",
    "\n",
    "A function $$ T(n) = \\Theta(f(n)) $$ if there exist constants $$ c_1, c_2 > 0 $$ and $$ n_0 \\geq 0 $$ such that:\n",
    "\n",
    "$$\n",
    "c_1 \\cdot f(n) \\leq T(n) \\leq c_2 \\cdot f(n) \\quad \\text{for all } n \\geq n_0\n",
    "$$\n"
   ],
   "id": "2524cc2a5c42fa6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Example:\n",
    "If $$T(n) = 3n + 2$$ then:\n",
    "\n",
    "$$T(n) = \\Theta(n)$$\n",
    "\n"
   ],
   "id": "fe767997daf61b31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
